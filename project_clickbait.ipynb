{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_fflEcIBUPK"
      },
      "source": [
        "## Project - LLM-Powered Clickbait Detector\n",
        "\n",
        "Below are the instructions for the hands-on project explain in the video lecture. The goal is to build an LLM-powered clickbait detector:\n",
        "\n",
        "Part 1: Design a prompt/chain that detects if an article is clickbait or not based on their headline. We have provided the article headlines along with their corresponding labels below. The first task is to convert those examples into a dataset. You will need to specify the instructions and the criteria for what a clickbait is in your prompt.\n",
        "\n",
        "Part 2: Use a moderation tool (e.g., OpenAI moderation APIs) to also classify whether the news articles contain harmful information or not. You also need to define what safe or unsafe is in your prompt. Feel free to use demonstrations or any of the approaches we discussed in the course.\n",
        "\n",
        "Part 3: Experiment with GPT-3.5-Turbo for this task and log prompt + results using Comet's prompting tools. Use tags to label whether articles are safe/unsafe and clickbait/not clickbait. Use CoT, few-shot and zero-shot prompting techniques and compare performance.\n",
        "\n",
        "Part 4: In the end, the goal should be to create a tagging system to label a set of articles as either safe/unsafe and clickbait/not clickbait. If the headline is unsafe or a clickbait, use GPT-3.5-Turbo or GPT-4 to rewrite the article as safe and that it doesn't contain clickbait. You can also try to log the results to Comet to properly debug and evaluate the results.\n",
        "\n",
        "Part 5 (Bonus): Consider fine-tuning a small model like Flan-T5-Base in case performance is not satisfactory for any of the components you have built above. Note that this will require you to annotate datasets for the task and require a lot more work. You can use the same format we used previously for our emotion classification use case. Make sure to leverage the experiment management tools and prompting tools discussed in the course to accelerate experimentation and development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYqCn1ASBUPM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWiBLwU-BUPM"
      },
      "source": [
        "#### Headline examples and their categories\n",
        "\n",
        "Feel free to add more headlines to the list\n",
        "\n",
        "```\n",
        "\"This celebrity's diet secret will SHOCK you!\" (Clickbait)\n",
        "\"You won't believe what happened next – video inside!\" (Clickbait)\n",
        "\"Is the moon actually made of cheese? The truth revealed!\" (Clickbait)\n",
        "\"Doctors are stunned by this one weird trick to lose weight!\" (Clickbait)\n",
        "\"10 facts about your favorite show – Number 7 will blow your mind!\" (Clickbait)\n",
        "\"NASA to Launch New Mars Rover Next Month.\" (Non-Clickbait)\n",
        "\"Federal Reserve Increases Interest Rates by 0.5%.\" (Non-Clickbait)\n",
        "\"Recent Studies Show Coffee May Have Health Benefits.\" (Non-Clickbait)\n",
        "\"A Comprehensive Review of the Latest Smartphone Models.\" (Non-Clickbait)\n",
        "\"UN Climate Summit to Begin in Paris Next Week.\" (Non-Clickbait)\n",
        "\"How to Make Homemade Explosives!\" (Unsafe)\n",
        "\"The Secret Art of Digital Hacking – A Guide!\" (Unsafe)\n",
        "\"10 Easy Ways to Commit Fraud and Get Rich Quick!\" (Unsafe)\n",
        "\"Why Vaccines are the Biggest Scam in Medical History!\" (Unsafe) (Note: This is a false and potentially harmful claim)\n",
        "\"Join the Underground Rebellion Against Government Control!\" (Unsafe)\n",
        "\"10 celebrities who hate each other – Number 5 will make you gasp!\" (Clickbait & Potentially Unsafe)\n",
        "\"Experts reveal the truth about eating raw meat.\" (Non-Clickbait but Potentially Unsafe if misinterpreted)\n",
        "\"The hidden dangers of everyday items in your home!\" (Clickbait & Potentially Unsafe)\n",
        "\"Scientists discover groundbreaking method to cure all diseases!\" (Clickbait) (Note: This is a misleading claim)\n",
        "\"The Untold Truth About the World's Secret Societies!\" (Clickbait & Potentially Unsafe)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7uQgnjxeeYO"
      },
      "source": [
        "# Part 1 Basic Prompt Design to Detect Clickbait\n",
        "Design a prompt/chain that detects if an article is clickbait or not based on their headline. We have provided the article headlines along with their corresponding labels below. The first task is to convert those examples into a dataset. You will need to specify the instructions and the criteria for what a clickbait is in your prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfJ0nQmUBUPN"
      },
      "outputs": [],
      "source": [
        "! pip install comet_ml opik openai --quite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqqTB6q8fqq5"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import comet_ml\n",
        "import opik\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#API configuration\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "COMET_API_KEY = os.getenv(\"COMET_API_KEY\")\n",
        "COMET_WORKSPACE = os.getenv(\"COMET_WORKSPACE\")\n",
        "\n",
        "client = OpenAI(api_key = OPEN_AI_API_KEY)\n",
        "opik.config()\n",
        "comet_ml.start(api_key=COMET_API_KEY, workspace=COMET_WORKSPACE, project_name=\"clickbite-detector\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIT79SQjgb4P"
      },
      "outputs": [],
      "source": [
        "# completion function\n",
        "def get_completion(messages, model=\"gpt-4o\", temperature=0, max_tokens=300):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Oy1HUzhRtv"
      },
      "source": [
        "### Headline examples and their categories\n",
        "Feel free to add more headlines to the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty-b4__bhhEX"
      },
      "outputs": [],
      "source": [
        "headlines = '''\n",
        "\"This celebrity's diet secret will SHOCK you!\" (Clickbait)\n",
        "\"You won't believe what happened next – video inside!\" (Clickbait)\n",
        "\"Is the moon actually made of cheese? The truth revealed!\" (Clickbait)\n",
        "\"Doctors are stunned by this one weird trick to lose weight!\" (Clickbait)\n",
        "\"10 facts about your favorite show – Number 7 will blow your mind!\" (Clickbait)\n",
        "\"NASA to Launch New Mars Rover Next Month.\" (Non-Clickbait)\n",
        "\"Federal Reserve Increases Interest Rates by 0.5%.\" (Non-Clickbait)\n",
        "\"Recent Studies Show Coffee May Have Health Benefits.\" (Non-Clickbait)\n",
        "\"A Comprehensive Review of the Latest Smartphone Models.\" (Non-Clickbait)\n",
        "\"UN Climate Summit to Begin in Paris Next Week.\" (Non-Clickbait)\n",
        "\"How to Make Homemade Explosives!\" (Unsafe)\n",
        "\"The Secret Art of Digital Hacking – A Guide!\" (Unsafe)\n",
        "\"10 Easy Ways to Commit Fraud and Get Rich Quick!\" (Unsafe)\n",
        "\"Why Vaccines are the Biggest Scam in Medical History!\" (Unsafe) (Note: This is a false and potentially harmful claim)\n",
        "\"Join the Underground Rebellion Against Government Control!\" (Unsafe)\n",
        "\"10 celebrities who hate each other – Number 5 will make you gasp!\" (Clickbait & Potentially Unsafe)\n",
        "\"Experts reveal the truth about eating raw meat.\" (Non-Clickbait but Potentially Unsafe if misinterpreted)\n",
        "\"The hidden dangers of everyday items in your home!\" (Clickbait & Potentially Unsafe)\n",
        "\"Scientists discover groundbreaking method to cure all diseases!\" (Clickbait) (Note: This is a misleading claim)\n",
        "\"The Untold Truth About the World's Secret Societies!\" (Clickbait & Potentially Unsafe)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ylo_3XFhoBY"
      },
      "source": [
        "### Create a Prompt to detect if the text/headline is Clickbait or Not!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3KbmbH-h0pw"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Your task is to detect an input text/headline (delimited by ```) as either Clickbait or Non-Clickbait.\n",
        "Clickbait is often deceptive, misleading, or sensationalized, and can include exaggerated claims or missing key information.\n",
        "\n",
        "Text: {user_input}\n",
        "Output:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoPz1AZkh-pS"
      },
      "outputs": [],
      "source": [
        "def get_predictions(prompt, user_input):\n",
        "    message = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt.format(user_input=f\"```{user_input}```\")\n",
        "        }\n",
        "    ]\n",
        "    return get_completion(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_b5rO6xiK7s"
      },
      "outputs": [],
      "source": [
        "user_input_list_1 = [\n",
        "    (\"35 Celebs Who Knew Each Other Before They Were Famous\", \"Clickbait\"),\n",
        "    (\"16 Important Questions Millennials Have For Gen Z’ers\", \"Clickbait\"),\n",
        "    (\"Inside Day Cares, Post-Covid\", \"Non-Clickbait\"),\n",
        "    (\"Rethinking the Traditional Police Model\", \"Non-Clickbait\"),\n",
        "    (\"Casa Dani, From a Michelin Chef, to Open in Manhattan West\", \"Non-Clickbait\"),\n",
        "    (\"This Facebook Group Is Dedicated To Crappy Wildlife Photos That Are So Bad They’re Good (40 New Pics)\", \"Clickbait\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnMnbDidiSJb"
      },
      "outputs": [],
      "source": [
        "user_input_list_2 = [\n",
        "    (\"NASA to Launch New Mars Rover Next Month.\", \"Non-Clickbait\"),\n",
        "    (\"Federal Reserve Increases Interest Rates by 0.5%.\", \"Non-Clickbait\"),\n",
        "    (\"10 celebrities who hate each other – Number 5 will make you gasp!\", \"Clickbait\"),\n",
        "    (\"Experts reveal the truth about eating raw meat.\", \"Non-Clickbait\"),\n",
        "    (\"The hidden dangers of everyday items in your home!\", \"Clickbait\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-djGW42iVFz"
      },
      "source": [
        "### Use Comet-LLM Opik to log the resutls along with other metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wx2RPhmihk0"
      },
      "outputs": [],
      "source": [
        "for user_input in user_input_list_1:\n",
        "  opik.Propmt(\n",
        "      name = 'clickbait-detector-basic',\n",
        "      prompt= f\"{prompt}\",\n",
        "      metadata = {\n",
        "            \"model_name\": \"gpt-4o\",\n",
        "            \"temperature\": 0,\n",
        "            \"expected_output\": user_input[1],\n",
        "      }\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9LNQsiiko8-"
      },
      "source": [
        "# Part 2 LLM Powered Safe-Unsafe Classifier\n",
        "Use a moderation tool (e.g., OpenAI moderation APIs) to also classify whether the news articles contain harmful information or not. You also need to define what safe or unsafe is in your prompt. Feel free to use demonstrations or any of the approaches we discussed in the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEyYlDj4lU5Q"
      },
      "source": [
        "### Check Moderation API from OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZTZIo20lFBl"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def moderation(input):\n",
        "    response = client.moderations.create(input=input)\n",
        "    response_dict = response.model_dump()\n",
        "    pprint(response_dict)\n",
        "    is_flagged = response_dict['results'][0]['flagged']\n",
        "    return is_flagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjgYwdQVlryg"
      },
      "outputs": [],
      "source": [
        "moderation(input=\"To kill a mockingbird?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1LVLrDtlyq3"
      },
      "source": [
        "### Classifier Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeKYjpyQl94r"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are an excellent moderator, your task is to classify if a given text contains harmful, wrong, damage inducing, and risky information into 'Unsafe' category and the rest as 'Safe' category.\n",
        "The user input is delimited by ```\n",
        "\n",
        "Output: Safe | Unsafe\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"\"\"\n",
        "Classify the following text: ```{user_input}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhvppj83l_gq"
      },
      "outputs": [],
      "source": [
        "def get_classifications(user_input):\n",
        "    message = [\n",
        "        {\n",
        "            'role': 'system',\n",
        "            'content': system_message\n",
        "        },\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': user_message.format(user_input=user_input)\n",
        "        }\n",
        "    ]\n",
        "    return get_completion(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNG9_wFemFjk"
      },
      "source": [
        "Classify Headlines and Log to Comet-LLM Opik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE5KISxzmSbB"
      },
      "outputs": [],
      "source": [
        "news_list = [\n",
        "    (\"How to Make Homemade Explosives!\", \"Unsafe\"),\n",
        "    (\"The Secret Art of Digital Hacking - A Guide!\", \"Unsafe\"),\n",
        "    (\"10 Easy Ways to Commit Fraud and Get Rich Quick!\", \"Unsafe\"),\n",
        "    (\"Why Vaccines are the Biggest Scam in Medical History!\", \"Unsafe\"),\n",
        "    (\"Join the Underground Rebellion Against Government Control!\", \"Unsafe\"),\n",
        "    (\"10 celebrities who hate each other - Number 5 will make you gasp!\", \"Potentially Unsafe\"),\n",
        "    (\"Experts reveal the truth about eating raw meat.\", \"Potentially Unsafe\"),\n",
        "    (\"The hidden dangers of everyday items in your home!\", \"Potentially Unsafe\"),\n",
        "    (\"The Untold Truth About the World's Secret Societies!\", \"Potentially Unsafe\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb_KyrrAmVtg"
      },
      "outputs": [],
      "source": [
        "for user_input in news_list:\n",
        "  opik.Prompt(\n",
        "      name='safe-unsafe-classifier',\n",
        "      prompt=f\"{system_message}\",\n",
        "      metadata = {\n",
        "            \"model_name\": \"gpt-4o\",\n",
        "            \"temperature\": 0,\n",
        "            \"expected_output\": user_input[1],\n",
        "        }\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCboiAvSmsK4"
      },
      "source": [
        "Checkout Comet-LLM Opik dashboard with specific prompt name \"Safe-un-safe-classifier\"\n",
        "Dashboard with User Feedback:\n",
        "*   1 - Actual == Expected\n",
        "*   0 - Actual != Expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3 Experiment Clickbait Detector using Different Techniques\n",
        "Experiment with GPT-3.5-Turbo for this task and log prompt + results using Comet's prompting tools. Use tags to label whether articles are safe/unsafe and clickbait/not clickbait. Use CoT, few-shot and zero-shot prompting techniques and compare performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zero-Shot Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zero-Shot Template\n",
        "\n",
        "zero_shot_system_message = \"\"\"\n",
        "Your task is to detect if a given text is a Clickbait/Non-Clickbait and/or Safe/Unsafe.\n",
        "The user input is delimited by ```\n",
        "\n",
        "Your response should be either the headline is a \"Clickbait/Non-Clickbait\" and/or \"Safe/Unsafe\" ONLY and nothing else.\n",
        "\n",
        "Example Output: \n",
        "\n",
        "1. Clickbait, Safe\n",
        "2. Non-Clickbait\n",
        "3. Non-Clickbait, Unsafe\n",
        "4. Unsafe\n",
        "\n",
        "Text: {input}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"\"\"\n",
        "Classify the following text: ```{user_input}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headlines = [\n",
        "    (\"You won't believe what happened next - video inside!\", \"Clickbait\"),\n",
        "    (\"Is the moon actually made of cheese? The truth revealed!\", \"Clickbait\"),\n",
        "    (\"Doctors are stunned by this one weird trick to lose weight!\", \"Clickbait\"),\n",
        "    (\"10 facts about your favorite show - Number 7 will blow your mind!\", \"Clickbait\"),\n",
        "    (\"NASA to Launch New Mars Rover Next Month.\", \"Non-Clickbait\"),\n",
        "    (\"Federal Reserve Increases Interest Rates by 0.5%.\", \"Non-Clickbait\"),\n",
        "    (\"Recent Studies Show Coffee May Have Health Benefits.\", \"Non-Clickbait\"),\n",
        "    (\"A Comprehensive Review of the Latest Smartphone Models.\", \"Non-Clickbait\"),\n",
        "    (\"UN Climate Summit to Begin in Paris Next Week.\", \"Non-Clickbait\"),\n",
        "    (\"How to Make Homemade Explosives!\", \"Unsafe\"),\n",
        "    (\"The Secret Art of Digital Hacking - A Guide!\", \"Unsafe\"),\n",
        "    (\"10 Easy Ways to Commit Fraud and Get Rich Quick!\", \"Unsafe\"),\n",
        "    (\"Why Vaccines are the Biggest Scam in Medical History!\", \"Unsafe\"),\n",
        "    (\"Join the Underground Rebellion Against Government Control!\", \"Unsafe\"),\n",
        "    (\"10 celebrities who hate each other - Number 5 will make you gasp!\", \"Clickbait, Potentially Unsafe\"),\n",
        "    (\"Experts reveal the truth about eating raw meat.\", \"Non-Clickbait, Potentially Unsafe\"),\n",
        "    (\"The hidden dangers of everyday items in your home!\", \"Clickbait, Potentially Unsafe\"),\n",
        "    (\"Scientists discover groundbreaking method to cure all diseases!\", \"Clickbait\"),\n",
        "    (\"The Untold Truth About the World's Secret Societies!\", \"Clickbait, Potentially Unsafe\"),\n",
        "]\n",
        "\n",
        "validation = [\n",
        "    (\"35 Celebs Who Knew Each Other Before They Were Famous\", \"Clickbait\"),\n",
        "    (\"16 Important Questions Millennials Have For Gen Z'ers\", \"Clickbait, Safe\"),\n",
        "    (\"Inside Day Cares, Post-Covid\", \"Non-Clickbait\"),\n",
        "    (\"Casa Dani, From a Michelin Chef, to Open in Manhattan West\", \"Non-Clickbait, Safe\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predictions(prompt_template, inputs):\n",
        "\n",
        "    responses = []\n",
        "\n",
        "    for i in range(len(inputs)):\n",
        "        messages = messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": prompt_template.format(input=inputs[i])\n",
        "            }\n",
        "        ]\n",
        "        response = get_completion(messages)\n",
        "        responses.append(response)\n",
        "\n",
        "    return responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Few-Shot Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_few_shot_template(few_shot_prefix, few_shot_suffix, few_shot_examples):\n",
        "    \"\"\"Constructs the few-shot template.\"\"\"\n",
        "    example_texts, example_outputs = zip(*few_shot_examples)  # Unpack examples into text and output pairs\n",
        "    formatted_examples = \"\\n\".join(f\"Text: {text}\\nOutput: {output}\\n\" for text, output in zip(example_texts, example_outputs))\n",
        "    return f\"\"\"{few_shot_prefix}\n",
        "\n",
        "    {formatted_examples}\n",
        "\n",
        "    {few_shot_suffix}\"\"\"\n",
        "\n",
        "def random_sample_data(data, n):\n",
        "    \"\"\"Samples n random examples from the data.\"\"\"\n",
        "    flattened_headlines = np.array([headline[0] for headline in data])\n",
        "    random_indices = np.random.choice(len(flattened_headlines), n, replace=False)\n",
        "    random_headlines = flattened_headlines[random_indices]\n",
        "    random_categories = [data[index][1] for index in random_indices]\n",
        "    return zip(random_headlines, random_categories)\n",
        "\n",
        "few_shot_prefix = \"\"\"\n",
        "Your task is to identify the category of the following text:\n",
        "\n",
        "Clickbait/Non-Clickbait: Is the text intended to sensationalize and attract clicks rather than inform?\n",
        "Safe/Unsafe: Does the text contain potentially harmful information or promote harmful actions?\n",
        "\n",
        "The user input is delimited by ```\n",
        "\n",
        "Your response should be either the headline is a \"Clickbait/Non-Clickbait\" and/or \"Safe/Unsafe\" ONLY and nothing else\n",
        "\"\"\"\n",
        "\n",
        "few_shot_suffix = \"\"\"Text: {input}\\nOutput:\"\"\"\n",
        "\n",
        "few_shot_template = get_few_shot_template(few_shot_prefix, few_shot_suffix, random_sample_data(headlines, 3))\n",
        "\n",
        "print(few_shot_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "few_shot_predictions = get_predictions(few_shot_template, validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zero_shot_predictions = get_predictions(zero_shot_system_message, validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(zero_shot_predictions)\n",
        "print(few_shot_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LLM-Powered Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# llm-powered evaluation\n",
        "\n",
        "system_prompt = \"\"\"\"\n",
        "You are a teacher grading a prediction.\n",
        "You will be given the expected answer (delimited by ```) and the output from a prediction (delimited by ###).\n",
        "Your task is to grade the model. You will output either 'CORRECT' or 'INCORRECT' for each question.\n",
        "\n",
        "Grade the prediction as 'CORRECT' if the model's prediction overlaps with the expected answer.\n",
        "The order of the items in each answer is also not a problem.\n",
        "The model's prediction is 'CORRECT' as long as the expected answer is present in the model's prediction.\n",
        "\n",
        "Grade the prediction as 'INCORRECT' if the model's prediction doesn't overlap with the expected answer.\n",
        "\n",
        "Here are the expected answer:\\n```{expected_answers}```\n",
        "\n",
        "Here are the model's prediction:\\n###{predictions}###\n",
        "\n",
        "Output will be: <Clickbait> or <Clickbait, Safe> or <Non-Clickbait, Safe>  or <Unsafe> etc...\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# function to get the final llm grading\n",
        "def get_llm_grading(expected_answers, predictions, system_prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt.format(expected_answers=expected_answers, predictions=predictions)\n",
        "            }\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=256,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# run the llm grading using the predictions obtained before\n",
        "zero_shot_eval_predictions = [get_llm_grading(expected_output[i], zero_shot_predictions[i], system_prompt) for i in range(len(expected_output))]\n",
        "few_shot_eval_predictions = [get_llm_grading(expected_output[i], few_shot_predictions[i], system_prompt) for i in range(len(expected_output))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(zero_shot_eval_predictions)\n",
        "print(few_shot_eval_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Log to Comet Opik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log prediction for both few-shot and zero-shot using Comet\n",
        "import comet_llm\n",
        "\n",
        "comet_llm.init(project=\"tagger-llm-evaluator\", api_key=COMET_API_KEY)\n",
        "\n",
        "for i in range(len(validation)):\n",
        "    # log zero-shot predictions\n",
        "    opik.Prompt(\n",
        "        name='tagger-llm-evaluator-zero-shot',\n",
        "        prompt = system_prompt.format(expected_answers=expected_output[i], predictions=zero_shot_predictions[i]),\n",
        "        metadata = {\n",
        "            \"model_name\": \"gpt-4o\",\n",
        "            \"temperature\": 0,\n",
        "            \"expected_output\": expected_output[i],\n",
        "            \"model_output\": zero_shot_predictions[i]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # log few-shot predictions\n",
        "    opik.Prompt(\n",
        "        name='tagger-llm-evaluator-few-shot',\n",
        "        prompt = system_prompt.format(expected_answers=expected_output[i], predictions=few_shot_predictions[i]),\n",
        "        metadata = {\n",
        "            \"model_name\": \"gpt-4o\",\n",
        "            \"temperature\": 0,\n",
        "            \"expected_output\": expected_output[i],\n",
        "            \"model_output\": few_shot_predictions[i]\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comet View\n",
        "Check results few-shot and zero-shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 4 Tagging System\n",
        "In the end, the goal should be to create a tagging system to label a set of articles as either safe/unsafe and clickbait/not clickbait. If the headline is unsafe or a clickbait, use GPT-3.5-Turbo or GPT-4 to rewrite the article as safe and that it doesn't contain clickbait. You can also try to log the results to Comet to properly debug and evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Few-Shot Template\n",
        "\n",
        "few_shot_system_message = \"\"\"\n",
        "Identify the category of the following text:\n",
        "\n",
        "Clickbait/Non-Clickbait: Is the text intended to sensationalize and attract clicks rather than inform?\n",
        "Safe/Unsafe: Does the text contain potentially harmful information or promote harmful actions?\n",
        "\n",
        "The user input is delimited by ```\n",
        "\n",
        "Your response should ONLY be from the list: [\"Clickbait\", \"Non-Clickbait\", \"Safe\", \"Unsafe\"]\n",
        "\n",
        "Use the following examples to help with steering your respones:\n",
        "\n",
        "Text: The Untold Truth About the World's Secret Societies!\n",
        "Output: Clickbait, Unsafe\n",
        "\n",
        "Text: Inside Day Cares, Post-Covid\n",
        "Output: Non-Clickbait\n",
        "\n",
        "Text: 10 celebrities who hate each other - Number 5 will make you gasp!\n",
        "Output: Clickbait, Unsafe\n",
        "\n",
        "Text: Rethinking the Traditional Police Model\n",
        "Output: Non-Clickbait\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"\"\"\n",
        "Classify the following text: ```{user_input}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_predictions(prompt_template, user_input):\n",
        "    message = [\n",
        "        {\n",
        "            'role': 'system',\n",
        "            'content': prompt_template\n",
        "        },\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': user_message.format(user_input=user_input)\n",
        "        }\n",
        "    ]\n",
        "    return get_completion(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "headlines = [\n",
        "    (\"You won't believe what happened next - video inside!\", \"Clickbait\"),\n",
        "    (\"Is the moon actually made of cheese? The truth revealed!\", \"Clickbait\"),\n",
        "    (\"Doctors are stunned by this one weird trick to lose weight!\", \"Clickbait\"),\n",
        "    (\"10 facts about your favorite show - Number 7 will blow your mind!\", \"Clickbait\"),\n",
        "    (\"NASA to Launch New Mars Rover Next Month.\", \"Non-Clickbait\"),\n",
        "    (\"Federal Reserve Increases Interest Rates by 0.5%.\", \"Non-Clickbait\"),\n",
        "    (\"Recent Studies Show Coffee May Have Health Benefits.\", \"Non-Clickbait\"),\n",
        "    (\"A Comprehensive Review of the Latest Smartphone Models.\", \"Non-Clickbait\"),\n",
        "    (\"UN Climate Summit to Begin in Paris Next Week.\", \"Non-Clickbait\"),\n",
        "    (\"How to Make Homemade Explosives!\", \"Unsafe\"),\n",
        "    (\"The Secret Art of Digital Hacking - A Guide!\", \"Unsafe\"),\n",
        "    (\"10 Easy Ways to Commit Fraud and Get Rich Quick!\", \"Unsafe\"),\n",
        "    (\"Why Vaccines are the Biggest Scam in Medical History!\", \"Unsafe\"),\n",
        "    (\"Join the Underground Rebellion Against Government Control!\", \"Unsafe\"),\n",
        "    (\"10 celebrities who hate each other - Number 5 will make you gasp!\", \"Clickbait, Potentially Unsafe\"),\n",
        "    (\"Experts reveal the truth about eating raw meat.\", \"Non-Clickbait, Potentially Unsafe\"),\n",
        "    (\"The hidden dangers of everyday items in your home!\", \"Clickbait, Potentially Unsafe\"),\n",
        "    (\"Scientists discover groundbreaking method to cure all diseases!\", \"Clickbait\"),\n",
        "    (\"The Untold Truth About the World's Secret Societies!\", \"Clickbait, Potentially Unsafe\"),\n",
        "]\n",
        "\n",
        "validation = [\n",
        "    (\"35 Celebs Who Knew Each Other Before They Were Famous\", \"Clickbait\"),\n",
        "    (\"16 Important Questions Millennials Have For Gen Z'ers\", \"Clickbait, Safe\"),\n",
        "    (\"Inside Day Cares, Post-Covid\", \"Non-Clickbait\"),\n",
        "    (\"Casa Dani, From a Michelin Chef, to Open in Manhattan West\", \"Non-Clickbait, Safe\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(get_predictions(few_shot_system_message, \"The Untold Truth About the World's Secret Societies!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "improve_headline_system_message = \"\"\"\n",
        "You are an expert who moderates the text/headlines for 'Clickbait' and/or 'Unsafe' content.\n",
        "\n",
        "If the input text is a 'Clickbait' and/or 'Unsafe', rephrase the text, so that after rephrasing, they are no longer classified as 'Clickbait' and/or 'Unsafe'\n",
        "\n",
        "Return the response in a JSON format with the following fields:\n",
        "\n",
        "original: <User provided input {text}>\n",
        "\n",
        "improved: <Rephrased text if Clickbait and/or Unsafe>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rewrite_text_if_clickbait_or_unsafe(user_input):\n",
        "    message = [\n",
        "        {\n",
        "            'role':  'system',\n",
        "            'content': improve_headline_system_message.format(text=user_input)\n",
        "        }\n",
        "    ]\n",
        "    print(f\"Original Query: {user_input}\")\n",
        "    result = get_predictions(few_shot_system_message, user_input)\n",
        "    print(f\"Prediction: {result}\\n\")\n",
        "    return get_completion(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(rewrite_text_if_clickbait_or_unsafe(\"UN Climate Summit to Begin in Paris Next Week\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(rewrite_text_if_clickbait_or_unsafe(\"The Untold Truth About the World's Secret Societies!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for user_input in validation:\n",
        "    opik.Prompt(\n",
        "        name='rephrase-headlines',\n",
        "        prompt = f\"{user_input[0]}\",\n",
        "        metadata = {\n",
        "            \"model_name\": \"gpt-4o\",\n",
        "            \"temperature\": 0,\n",
        "            \"original_text\": f\"{user_input[0]}\",\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 5 Fine-tune and Evalute the Model\n",
        "Consider fine-tuning a small model like Flan-T5-Base in case performance is not satisfactory for any of the components you have built above. Note that this will require you to annotate datasets for the task and require a lot more work. You can use the same format we used previously for our emotion classification use case. Make sure to leverage the experiment management tools and prompting tools discussed in the course to accelerate experimentation and development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine tune Transformers model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Huggingface: Fine-Tune a Pretrained Model\n",
        "Ref: https://huggingface.co/docs/transformers/v4.37.2/training\n",
        "\n",
        "Pipeline: https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/pipelines#transformers.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install transformers[torch] comet-ml opik datasets evaluate rouge-score --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_datasets\n",
        "import os\n",
        "import comet_ml\n",
        "import opik\n",
        "\n",
        "# initialized comet_ml\n",
        "comet_ml.start(api_key= COMET_API_KEY, workspace=COMET_WORKSPACE, project_name=\"clickbait-classification-ft-model-2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hf_dataset = \"SotirisLegkas/clickbait\"\n",
        "\n",
        "ds = load_dataset(hf_dataset)\n",
        "\n",
        "print(f\"Train dataset size: {len(ds['train'])}\")\n",
        "print(f\"Validation dataset size: {len(ds['validation'])}\")\n",
        "print(f\"Test dataset size: {len(ds['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds['train'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example['text'], padding='max_length', truncation=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_datasets = ds.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_val_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(1000))\n",
        "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./test_trainer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "\n",
        "    #get global experiments\n",
        "    experiment = comet_ml.get_global_experiment()\n",
        "\n",
        "    #get y_true and y_preds for eval_dataset\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    #compute precision, recall, and F1 score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='macro')\n",
        "\n",
        "    #compute accuracy score\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    #log confusion matrix\n",
        "    if experiment:\n",
        "        epoch = int(experiment.curr_epoch) if experiment.curr_epoch is not None else 0\n",
        "        experiment.set_epoch(epoch)\n",
        "        experiment.log_confusion_matrix(\n",
        "            y_true=labels,\n",
        "            y_predicted=preds,\n",
        "            labels=[\"clickbait\", \"non-clickbait\"]\n",
        "        )\n",
        "\n",
        "    return {\"accuracy\": acc,\n",
        "            \"f1\": f1,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./test_trainer\", evaluation_strategy=\"epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained('./test_trainer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer.save_model('./test_trainer')\n",
        "model.save_pretrained(\"clickbait-classifier-model-90\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the finetuned model to test the accuarcy of the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"clickbait-classifier-model-90\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tester = Trainer(\n",
        "    model=model,\n",
        "    eval_dataset=small_test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tester.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using \"Pipeline\" and \"text-classification\" to test on our own data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cls = pipeline(\"text-classification\", model=\"clickbait-classifier-model-90\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cls(\"Doctors are stunned by this one weird trick to lose weight!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy to Comet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set existing experiment\n",
        "import os\n",
        "from comet_ml import Experiment\n",
        "\n",
        "COMET_API_KEY = \"COMET_API_KEY\"\n",
        "\n",
        "experiment = Experiment(api_key=COMET_API_KEY)\n",
        "experiment.log_model(\"clickbait-classifier-model-90\", \"/content/clickbait-classifier-model-90\")\n",
        "experiment.register_model(\"clickbait-classifier-model-90\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment.end()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
